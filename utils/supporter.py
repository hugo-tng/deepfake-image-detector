import torch
import os
import random
import numpy as np
from models.detector import DeepfakeDetector
from utils.config import TrainingConfig, GlobalConfig

def set_seed(seed: int = 42, deterministic: bool = True):
    """
    Set random seed for full reproducibility.
    
    Args:
        seed (int): Random seed
        deterministic (bool): If True, enforce deterministic behavior (slower)
    """
    # Python
    random.seed(seed)
    os.environ["PYTHONHASHSEED"] = str(seed)

    # NumPy
    np.random.seed(seed)

    # PyTorch
    torch.manual_seed(seed)
    torch.cuda.manual_seed(seed)
    torch.cuda.manual_seed_all(seed)

    if deterministic:
        # CuDNN
        torch.backends.cudnn.deterministic = True
        torch.backends.cudnn.benchmark = False

        # Torch >= 1.8
        torch.use_deterministic_algorithms(True)
    else:
        # Faster but non-deterministic
        torch.backends.cudnn.deterministic = False
        torch.backends.cudnn.benchmark = True

    print(f"[INFO] Random seed set to {seed} | deterministic={deterministic}")


def build_model(config: TrainingConfig):
    """
    Factory function ƒë·ªÉ kh·ªüi t·∫°o model.
    
    Args:
        config: Class TrainingConfig ch·ª©a c·∫•u h√¨nh
        mode (str, optional): N·∫øu mu·ªën override mode trong config (vd: test nh√°nh l·∫ª)
    
    Returns:
        model: M√¥ h√¨nh ƒë√£ ƒë∆∞·ª£c ƒë·∫©y l√™n Device (GPU/CPU)
    """
    # S·ª≠ d·ª•ng mode t·ª´ tham s·ªë ho·∫∑c t·ª´ config
    selected_mode = config.MODE

    print(f"üõ†Ô∏è Building Model | Mode: {selected_mode} | Device: {GlobalConfig.DEVICE}")

    model = DeepfakeDetector(
        mode=selected_mode,
        **config.MODEL_CONFIG
    )

    model.to(GlobalConfig.DEVICE)
    return model

def load_weights(model, config: TrainingConfig):
    """
    Load tr·ªçng s·ªë t·ª´ file .pth v√†o model m·ªôt c√°ch an to√†n.
    T·ª± ƒë·ªông x·ª≠ l√Ω tr∆∞·ªùng h·ª£p key ch·ª©a 'module.' (do train DataParallel).
    
    Args:
        model: Ki·∫øn tr√∫c model ƒë√£ kh·ªüi t·∫°o
        checkpoint_path: ƒê∆∞·ªùng d·∫´n ƒë·∫øn file .pth
        device: Torch device
    
    Returns:
        model: Model ƒë√£ load tr·ªçng s·ªë v√† chuy·ªÉn sang eval mode
        info: Dict ch·ª©a th√¥ng tin th√™m (epoch, metrics...)
    """
    checkpoint_path = os.path.join(config.CHECKPOINT_DIR, "best_model.pth")
    if not os.path.exists(config.CHECKPOINT_DIR):
        raise FileNotFoundError(f"‚ùå Kh√¥ng t√¨m th·∫•y file tr·ªçng s·ªë t·∫°i: {checkpoint_path}")
        
    print(f"üîÑ Loading weights from: {checkpoint_path}")
    
    # Load checkpoint
    checkpoint = torch.load(checkpoint_path, map_location=GlobalConfig.DEVICE)
    
    # L·∫•y state_dict
    if 'model_state_dict' in checkpoint:
        state_dict = checkpoint['model_state_dict'] # Checkpoint ƒë·∫ßy ƒë·ªß
    else:
        state_dict = checkpoint # Ch·ªâ l∆∞u state_dict
        
    # X·ª≠ l√Ω key 'module.' (n·∫øu train nhi·ªÅu GPU)
    new_state_dict = {}
    for k, v in state_dict.items():
        name = k[7:] if k.startswith('module.') else k 
        new_state_dict[name] = v
        
    # Load v√†o model
    try:
        model.load_state_dict(new_state_dict, strict=True)
    except RuntimeError as e:
        print(f"‚ö†Ô∏è Warning: Key mismatch (Strict loading failed). Retrying with strict=False.")
        print(f"Error detail: {e}")
        model.load_state_dict(new_state_dict, strict=False)
        
    model.to(GlobalConfig.DEVICE)
    model.eval() # chuy·ªÉn sang eval mode khi load
    
    print("‚úÖ Weights loaded successfully!")
    
    # Tr·∫£ v·ªÅ th√¥ng tin epoch/metrics n·∫øu c√≥
    info = {
        'epoch': checkpoint.get('epoch', -1),
        'metrics': checkpoint.get('metrics', {})
    }
    return model, info


def count_parameters(model):
    """H√†m ph·ª• tr·ª£: ƒê·∫øm s·ªë l∆∞·ª£ng tham s·ªë trainable"""
    total_params = sum(p.numel() for p in model.parameters())
    trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)
    
    print(f"üìä Model Summary:")
    print(f"   Total parameters: {total_params:,}")
    print(f"   Trainable parameters: {trainable_params:,}")
    
    return total_params, trainable_params